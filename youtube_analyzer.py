import pandas as pd
from googleapiclient.discovery import build
import re
from collections import Counter
import os

# =========================================================
# âš™ï¸ [ì„¤ì •] API í‚¤ì™€ ê²€ìƒ‰ì–´
# =========================================================
API_KEY = "YOUR_API_KEY_HERE"  # <-- ë³¸ì¸ í‚¤ ì…ë ¥
SEARCH_KEYWORD = "ë‹¹ë‡¨"
FILE_NAME = "medical_final.csv"

# =========================================================
# 1. ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ (ETL: Extract)
# íŒŒì¼ì´ ì—†ìœ¼ë©´ ìœ íŠœë¸Œì—ì„œ ê¸ì–´ì˜¤ê³ , ìˆìœ¼ë©´ ê±´ë„ˆëœë‹ˆë‹¤.
# =========================================================
def get_or_create_data():
    # íŒŒì¼ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists(FILE_NAME):
        print(f"âœ… ê¸°ì¡´ ë°ì´í„° íŒŒì¼('{FILE_NAME}')ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë¡œë”© ì¤‘...")
        return pd.read_csv(FILE_NAME)
    
    print(f"ğŸš€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. '{SEARCH_KEYWORD}' ê´€ë ¨ ë°ì´í„°ë¥¼ ìƒˆë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
    
    # ìœ íŠœë¸Œ API ì—°ê²°
    youtube = build('youtube', 'v3', developerKey=API_KEY)
    
    # ë°ì´í„° ìˆ˜ì§‘ (50ê°œ)
    search_response = youtube.search().list(
        q=SEARCH_KEYWORD, part='id,snippet', maxResults=50, 
        type='video', order='viewCount'
    ).execute()
    
    video_ids = [item['id']['videoId'] for item in search_response['items']]
    video_response = youtube.videos().list(
        part='snippet,statistics', id=','.join(video_ids)
    ).execute()
    
    data_list = []
    doctor_keywords = ['ì˜ì‚¬', 'ë‹¥í„°', 'dr', 'ë³‘ì›', 'ì•½ì‚¬', 'í•œì˜ì‚¬', 'ì „ë¬¸ì˜', 'êµìˆ˜', 'ì˜ì›', 'md']

    for item in video_response['items']:
        channel_name = item['snippet']['channelTitle']
        # ì „ë¬¸ê°€ vs ì¼ë°˜ì¸ ë¶„ë¥˜
        is_expert = "General"
        for key in doctor_keywords:
            if key in channel_name.lower(): 
                is_expert = "Medical Pro"
                break
        
        data_list.append({
            'Title': item['snippet']['title'],
            'Channel': channel_name,
            'Type': is_expert
        })
    
    df = pd.DataFrame(data_list)
    # CSV íŒŒì¼ë¡œ ì €ì¥ (í•œê¸€ ê¹¨ì§ ë°©ì§€ utf-8-sig)
    df.to_csv(FILE_NAME, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! '{FILE_NAME}'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    return df

# =========================================================
# 2. ë°ì´í„° í•™ìŠµ ëª¨ë“ˆ (Training)
# ì¼ë°˜ì¸ ìœ íŠœë²„ë“¤ì˜ ê³ íš¨ìœ¨ ë‹¨ì–´ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
# =========================================================
def train_model(df):
    print("ğŸ¤– ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì ìˆ˜í‘œë¥¼ ë§Œë“œëŠ” ì¤‘...")
    
    # ì¼ë°˜ì¸(General) ì˜ìƒì˜ ì œëª©ë§Œ ì¶”ì¶œ
    target_df = df[df['Type'] == 'General']
    titles = target_df['Title'].tolist()
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ë‹¨ì–´ ì¶”ì¶œ
    all_words = []
    stop_words = [SEARCH_KEYWORD, 'ë‹¹ë‡¨ë³‘', 'ì—', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ë°©ë²•', 'ê°€ì¥', 'ì§„ì§œ']
    
    for title in titles:
        clean_text = re.sub(r'[^\w\s]', '', title) # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        words = clean_text.split()
        # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ í•„í„°ë§
        meaningful_words = [w for w in words if w not in stop_words and len(w) > 1]
        all_words.extend(meaningful_words)
    
    # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ì ìˆ˜í‘œ ìƒì„±
    word_scores = Counter(all_words)
    return word_scores

# =========================================================
# 3. ì˜ˆì¸¡ ëª¨ë“ˆ (Inference)
# =========================================================
def predict_score(new_title, model):
    clean_title = re.sub(r'[^\w\s]', '', new_title)
    words = clean_title.split()
    
    total_score = 0
    matched_words = []
    
    for word in words:
        if word in model:
            # ë¹ˆë„ìˆ˜ 1íšŒë‹¹ 5ì ì”© ë¶€ì—¬ (ê°€ì¤‘ì¹˜)
            score = model[word] * 5
            total_score += score
            matched_words.append(f"{word}(+{score})")
            
    # ìˆ«ì í¬í•¨ ì‹œ ê°€ì‚°ì 
    if any(char.isdigit() for char in new_title):
        total_score += 10
        matched_words.append("ìˆ«ìí¬í•¨(+10)")
    
    # 100ì  ë§Œì ìœ¼ë¡œ ì œí•œ
    final_score = min(total_score, 100)
    
    # ë¦¬í¬íŠ¸ ì¶œë ¥
    print(f"\nğŸ“„ ì…ë ¥ ì œëª©: [{new_title}]")
    if matched_words:
        print(f"   ğŸ‘‰ ì ìˆ˜ ìš”ì¸: {', '.join(matched_words)}")
    else:
        print("   ğŸ‘‰ ì ìˆ˜ ìš”ì¸: ì—†ìŒ (ë„ˆë¬´ í‰ë²”í•©ë‹ˆë‹¤)")
    print(f"   ğŸ† ìµœì¢… ì ìˆ˜: {final_score}ì ")

# =========================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# =========================================================
if __name__ == "__main__":
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        df = get_or_create_data()
        
        # 2. ëª¨ë¸ í•™ìŠµ
        ai_model = train_model(df)
        
        print("\n" + "="*40)
        print("ğŸ’‰ ë‹¹ë‡¨ ìœ íŠœë¸Œ ì œëª© AI íŒë…ê¸°")
        print("="*40)
        
        # 3. ì‚¬ìš©ì í…ŒìŠ¤íŠ¸
        while True:
            user_input = input("\nâœï¸ ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: q): ")
            if user_input.lower() == 'q':
                break
            predict_score(user_input, ai_model)
            
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")